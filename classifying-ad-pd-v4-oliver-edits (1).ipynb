{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12000929,"sourceType":"datasetVersion","datasetId":7514614}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, LSTM, SimpleRNN\nfrom keras.optimizers import Adam\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tensorflow.keras import layers, models, optimizers\nimport keras\nfrom tensorflow.keras.applications import EfficientNetB0, VGG16\nfrom tensorflow.keras import * \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom skimage import io\nfrom tensorflow.keras.models import Model \nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, Xception\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport os\n# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, Xception\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.optimizers import Adam\nimport sklearn\nfrom tensorflow.keras.metrics import Precision, Recall\n# from sklearn.model_selection import GridSearchCV\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport os\nfrom sklearn.utils import class_weight\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as effnet_preprocess\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:18.193803Z","iopub.execute_input":"2025-06-04T17:28:18.194034Z","iopub.status.idle":"2025-06-04T17:28:33.506642Z","shell.execute_reply.started":"2025-06-04T17:28:18.194011Z","shell.execute_reply":"2025-06-04T17:28:33.506108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/classifying-ad-and-pd-v3/3_cls_2/train'\ntest_data_dir = '/kaggle/input/classifying-ad-and-pd-v3/3_cls_2/test'\nimage_size = (224, 224)\nimage_size2 = (600, 600) # EfficientNetB7\nbatch_size = 16\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:33.507732Z","iopub.execute_input":"2025-06-04T17:28:33.508198Z","iopub.status.idle":"2025-06-04T17:28:33.511967Z","shell.execute_reply.started":"2025-06-04T17:28:33.508173Z","shell.execute_reply":"2025-06-04T17:28:33.511287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        preprocessing_function=effnet_preprocess,\n        rotation_range=20,     #Random rotation between 0 and 45\n        width_shift_range=0.2,   #% shift\n        brightness_range=[0.8, 1.2],      # New: Random brightness\n        channel_shift_range=10.,          # New: Channel shift\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='constant', \n        cval=125,\n        rescale=1.0/255.0,\n        validation_split=0.1  # 20% of the data will be used for validation\n    ) \nval_datagen = ImageDataGenerator(\n    preprocessing_function=effnet_preprocess,\n    validation_split=0.1\n)\ntest_datagen = ImageDataGenerator(preprocessing_function=effnet_preprocess,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:33.512674Z","iopub.execute_input":"2025-06-04T17:28:33.512927Z","iopub.status.idle":"2025-06-04T17:28:33.527907Z","shell.execute_reply.started":"2025-06-04T17:28:33.512906Z","shell.execute_reply":"2025-06-04T17:28:33.527149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create ImageDataGenerators for training and validation with data augmentation\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'  # Use the 'training' subset\n)\n\n# Load the validation data\nvalidation_generator = val_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'  # Use the 'validation' subset\n) \n\n\n# Load the data\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n###################### EfficientNetB7\nbatch_size = 8 \n# Create ImageDataGenerators for training and validation with data augmentation\ntrain_generator2 = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=image_size2,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'  # Use the 'training' subset\n)\n\n# Load the validation data\nvalidation_generator2 = val_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=image_size2,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'  # Use the 'validation' subset\n) \n\n\n# Load the data\ntest_generator2 = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=image_size2,\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:33.528498Z","iopub.execute_input":"2025-06-04T17:28:33.528656Z","iopub.status.idle":"2025-06-04T17:28:36.824301Z","shell.execute_reply.started":"2025-06-04T17:28:33.528643Z","shell.execute_reply":"2025-06-04T17:28:36.823782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, y_train = next(train_generator)\nX_val, y_val = next(validation_generator)\nX_test, y_test = next(test_generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:36.825860Z","iopub.execute_input":"2025-06-04T17:28:36.826480Z","iopub.status.idle":"2025-06-04T17:28:37.485489Z","shell.execute_reply.started":"2025-06-04T17:28:36.826456Z","shell.execute_reply":"2025-06-04T17:28:37.484675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total = 0\nfor class_name in os.listdir(train_data_dir):\n    class_path = os.path.join(train_data_dir, class_name)\n    if os.path.isdir(class_path):\n        n = len([fname for fname in os.listdir(class_path)\n                 if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n        print(f\"{class_name}: {n} images\")\n        total += n\nprint(f\"Total images before augmentation: {total}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:37.486391Z","iopub.execute_input":"2025-06-04T17:28:37.486880Z","iopub.status.idle":"2025-06-04T17:28:37.496225Z","shell.execute_reply.started":"2025-06-04T17:28:37.486858Z","shell.execute_reply":"2025-06-04T17:28:37.495470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Train images used (after augmentation): {train_generator.samples}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:37.496961Z","iopub.execute_input":"2025-06-04T17:28:37.497586Z","iopub.status.idle":"2025-06-04T17:28:37.511179Z","shell.execute_reply.started":"2025-06-04T17:28:37.497559Z","shell.execute_reply":"2025-06-04T17:28:37.510583Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Note: new and old functions below \n\nI created a new **\"build_and_train_model()\"** function but also left the old one (just extended the name with \"_old\") below. The new function does the 2 step process of training and also freezes 80% of the layers of each model - allowing you to fine-tune 20% of the layers. You could always change this to get more specific with each model, but this is a solid generalized approach that I think works. ","metadata":{}},{"cell_type":"code","source":"initial_epochs=10\ndef build_and_train_model_two_phase(\n    model_name,\n    base_model,\n    train_generator,\n    validation_generator,\n    initial_epochs=initial_epochs,      # train head for 5–10 epochs\n    fine_tune_epochs=80,   # then fine-tune for approx 10–15 more (or even more than that?)\n    initial_lr=1e-4,\n    fine_tune_lr=3e-5,\n    dropout_rate=0.7\n):\n    \"\"\"\n    Two-phase training:\n      Phase 1: Freeze ~80% of base_model, train only head for initial_epochs.\n      Phase 2: Unfreeze last blocks of base_model, recompile with lower LR, continue training.\n    Returns: (fine-tuned_model, combined_history)\n    \"\"\"\n\n    # -----------------------------------------------------------\n    # STEP A: Freeze most of the base_model for Phase 1\n    # -----------------------------------------------------------\n    # 1) freeze the earliest 60 % of layers in base_model.\n    N = int(len(base_model.layers) * 0.6)  # a rough t0% cutoff by layer COUNT\n    for layer in base_model.layers[:N]:\n        layer.trainable = False\n\n    # 2) Unfreeze the remainder of the layers for Phase 1 (so the head can be trained on them, if desired).\n    for layer in base_model.layers[N:]:\n        layer.trainable = True\n\n    # now - base_model has 80% of its layers frozen, 20% trainable!\n\n    # -----------------------------------------------------------\n    # STEP B: Build & compile the full model (head + base)\n    # -----------------------------------------------------------\n    x = Flatten()(base_model.output)                        # Flatten the feature map\n    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)                    # One hidden Dense layer\n    x = Dropout(dropout_rate)(x)                            # Dropout for regularization\n    output = Dense(3, activation='softmax')(x)              # 3-way softmax for AD/PD/Control\n\n    model = Model(inputs=base_model.input, outputs=output)\n\n    # Compile with a “standard” learning rate for the head (Phase 1)\n    model.compile(\n        optimizer=Adam(learning_rate=initial_lr),\n        loss='categorical_crossentropy',\n        metrics=['accuracy', Precision(), Recall()]\n    )\n\n    # -----------------------------------------------------------\n    # STEP C: Compute class_weights \n    # -----------------------------------------------------------\n    classes = train_generator.classes\n    unique_classes = np.unique(classes)  # e.g. array([0,1,2])\n\n    weights = class_weight.compute_class_weight(\n        class_weight='balanced',\n        classes=unique_classes,\n        y=classes\n    )\n    class_weights = dict(zip(unique_classes, weights))\n\n    # -----------------------------------------------------------\n    # STEP D: Phase 1 — Train only the head (base_model is mostly frozen)\n    # -----------------------------------------------------------\n   # Learning rate reducer\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.3,\n        patience=2,\n        min_lr=1e-7,\n        verbose=2\n    )\n\n    # Early stopping\n    early_stop = EarlyStopping(\n        monitor='val_loss',\n        patience=12,    \n        restore_best_weights=True,\n        verbose=2\n    )\n    if (model_name != 'EfficientNetB7'): \n        print(\">>> PHASE 1: Training head (with ~80% of base frozen) <<<\")\n        history_phase1 = model.fit(\n            train_generator,\n            steps_per_epoch = train_generator.samples // train_generator.batch_size,\n            validation_data   = validation_generator,\n            validation_steps  = validation_generator.samples // validation_generator.batch_size,\n            epochs            = initial_epochs,\n            callbacks         = [reduce_lr, early_stop],\n            class_weight      = class_weights,\n            verbose           = 2\n        )\n    else:\n        print(\">>> PHASE 1: Training head (with ~80% of base frozen) <<<\")\n        history_phase1 = model.fit(\n            train_generator2,\n            steps_per_epoch = train_generator2.samples // train_generator2.batch_size,\n            validation_data   = validation_generator2,\n            validation_steps  = validation_generator2.samples // validation_generator2.batch_size,\n            epochs            = initial_epochs,\n            callbacks         = [reduce_lr, early_stop],\n            class_weight      = class_weights,\n            verbose           = 2\n        )\n\n    # -----------------------------------------------------------\n    # STEP E: Phase 2 — Unfreeze the final blocks of base_model\n    # -----------------------------------------------------------\n    print(\"\\n>>> PHASE 2: Fine-tuning top layers <<<\")\n    # (a) Freeze everything again first, then unfreeze only the final blocks by name/index.\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    # ** Here is where you unfreeze only the “last blocks” (approx 20% of layers) **\n    # You can either do: \n    #   (1) Replace the condition below with the exact block‐name rule for your architecture.\n    #   For example, if this is ResNet50, you might do:\n    #       if layer.name.startswith('conv5_') or layer.name.startswith('conv4_'): layer.trainable=True\n    #\n    #   -or- \n    #   (2) for simplicity - we’ll unfreeze everything from index N onward again:\n    for layer in base_model.layers[N:]:\n        layer.trainable = True\n\n    # (b) recompile with a lower learning rate (to avoid wrecking the pretrained weights)\n    model.compile(\n        optimizer=Adam(learning_rate=fine_tune_lr),\n        loss='categorical_crossentropy',\n        metrics=['accuracy', Precision(), Recall()]\n    )\n\n    # (c) continue training (starting from where Phase 1 left off) - with same class_weight\n    if (model_name != 'EfficientNetB7'):\n        history_phase2 = model.fit(\n            train_generator,\n            steps_per_epoch = train_generator.samples // train_generator.batch_size,\n            validation_data = validation_generator,\n            validation_steps = validation_generator.samples // validation_generator.batch_size,\n            epochs = initial_epochs + fine_tune_epochs,\n            initial_epoch = initial_epochs,  # resume from Phase 1\n            callbacks = [reduce_lr, early_stop],\n            class_weight = class_weights,\n            verbose = 2\n        )\n    else: \n        history_phase2 = model.fit(\n            train_generator2,\n            steps_per_epoch = train_generator2.samples // train_generator2.batch_size,\n            validation_data = validation_generator2,\n            validation_steps = validation_generator2.samples // validation_generator2.batch_size,\n            epochs = initial_epochs + fine_tune_epochs,\n            initial_epoch = initial_epochs,  # resume from Phase 1\n            callbacks = [reduce_lr, early_stop],\n            class_weight = class_weights,\n            verbose = 2\n        )\n\n    # -----------------------------------------------------------\n    # STEP F: Combine the histories so we can plot later if desired\n    # -----------------------------------------------------------\n    combined_history = {\n        'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n        'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss'],\n        'accuracy': history_phase1.history.get('accuracy', []) + history_phase2.history.get('accuracy', []),\n        'val_accuracy': history_phase1.history.get('val_accuracy', []) + history_phase2.history.get('val_accuracy', []),\n        'precision': history_phase1.history.get('precision', []) + history_phase2.history.get('precision', []),\n        'val_precision': history_phase1.history.get('val_precision', []) + history_phase2.history.get('val_precision', []),\n        'recall': history_phase1.history.get('recall', []) + history_phase2.history.get('recall', []),\n        'val_recall': history_phase1.history.get('val_recall', []) + history_phase2.history.get('val_recall', []),\n    }\n\n    return model, combined_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:37.511833Z","iopub.execute_input":"2025-06-04T17:28:37.512041Z","iopub.status.idle":"2025-06-04T17:28:37.527998Z","shell.execute_reply.started":"2025-06-04T17:28:37.512025Z","shell.execute_reply":"2025-06-04T17:28:37.527338Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_and_train_model_old(base_model, train_generator, validation_generator, epochs=50,learning_rate=0.0001, dropout_rate=0.5):\n    # Freeze the convolutional base\n    # base_model.trainable = False\n    # for layer in base_model.layers:\n    #     layer.trainable = False \n    N = 3\n    for layer in base_model.layers[:N]:\n        layer.trainable = False\n    for layer in base_model.layers[N:]:\n        layer.trainable = True\n\n    # Add custom classification layers\n    x = Flatten()(base_model.output)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(dropout_rate)(x)\n    output = Dense(3, activation='softmax')(x)  # 3 classes: Alzheimer's, Parkinson's, Control\n\n    # Create the model\n    model = Model(inputs=base_model.input, outputs=output)\n    \n    # Compile the model\n    learning_rate1 = float(1e-4)\n\n    model.compile(\n        optimizer=Adam(learning_rate=learning_rate1),\n        loss='categorical_crossentropy',\n        metrics=['accuracy', Precision(), Recall()]\n    )\n     \n\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_loss',    # or 'val_accuracy'\n        factor=0.5,            # reduce by half\n        patience=3,            # wait this many epochs with no improvement\n        min_lr=1e-7,           # never lower than this\n        verbose=1\n    )\n\n    from sklearn.utils import class_weight\n    import numpy as np\n    \n\n    classes = train_generator.classes\n    class_labels = np.unique(classes)\n    weights = class_weight.compute_class_weight(\n        class_weight='balanced',\n        classes=class_labels,\n        y=classes\n    )\n    class_weights = dict(zip(class_labels, weights))\n    \n    history = model.fit(\n        train_generator,\n        steps_per_epoch=train_generator.samples // batch_size,\n        validation_steps=validation_generator.samples // batch_size,\n        validation_data=validation_generator,\n        epochs=epochs,\n        callbacks=[reduce_lr],\n        class_weight=class_weights   # <-- singular\n    )\n    return model, history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:37.528710Z","iopub.execute_input":"2025-06-04T17:28:37.528972Z","iopub.status.idle":"2025-06-04T17:28:37.546288Z","shell.execute_reply.started":"2025-06-04T17:28:37.528950Z","shell.execute_reply":"2025-06-04T17:28:37.545747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\n\nclass TerminateOnMetric(Callback):\n    def __init__(self, monitor='accuracy', threshold=0.80):\n        super().__init__()\n        self.monitor = monitor\n        self.threshold = threshold\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        metric_value = logs.get(self.monitor)\n        if metric_value is not None:\n            if metric_value >= self.threshold:\n                print(f\"\\nReached {self.monitor} = {metric_value:.4f}, stopping training!\")\n                self.model.stop_training = True\n\n# Example usage:\ncallback = TerminateOnMetric(monitor='accuracy', threshold=0.80)\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:37.547057Z","iopub.execute_input":"2025-06-04T17:28:37.547278Z","iopub.status.idle":"2025-06-04T17:28:37.564824Z","shell.execute_reply.started":"2025-06-04T17:28:37.547264Z","shell.execute_reply":"2025-06-04T17:28:37.564140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" pretrained_models = {\n    'VGG16': VGG16(include_top=False, input_shape=(224, 224, 3), weights='imagenet', pooling='avg'),\n    'ResNet50': ResNet50(include_top=False, input_shape=(224, 224, 3), weights='imagenet', pooling='avg'),\n    'InceptionV3': InceptionV3(include_top=False, input_shape=(224, 224, 3), weights='imagenet', pooling='avg'),\n    'Xception': Xception(include_top=False, input_shape=(224, 224, 3), weights='imagenet', pooling='avg'),\n    'EfficientNetB0': EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights='imagenet', pooling='avg'),\n    'EfficientNetB7': EfficientNetB7(include_top=False, input_shape=(600, 600, 3), weights='imagenet', pooling='avg'),\n    \n}\n\n# Store the trained models and their histories\ntrained_models = {}\nhistories = {}\n\nfor model_name, base_model in pretrained_models.items():\n    print(f\"Training model: {model_name}\")\n    model, history = build_and_train_model_two_phase(model_name, base_model, train_generator, validation_generator)\n    trained_models[model_name] = model\n    histories[model_name] = history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:28:37.565568Z","iopub.execute_input":"2025-06-04T17:28:37.565845Z","iopub.status.idle":"2025-06-04T17:31:18.990477Z","shell.execute_reply.started":"2025-06-04T17:28:37.565824Z","shell.execute_reply":"2025-06-04T17:31:18.989730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" def evaluate_model(model, test_generator):\n    # Evaluate the model\n    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n    test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall + 1e-2)\n    \n    # Predict the classes for validation data\n    test_preds = model.predict(test_generator)\n    test_preds = np.argmax(test_preds, axis=1)\n    test_true = test_generator.classes\n    \n    # Generate confusion matrix\n    cm = confusion_matrix(test_true, test_preds)\n    \n    return test_accuracy, test_precision, test_recall, test_f1, cm\n\nresults = []\ntest_accuracies = []\nfor model_name, model in trained_models.items():\n    print(f\"Evaluating model: {model_name}\")\n    test_accuracy, test_precision, test_recall, test_f1, cm = evaluate_model(model, validation_generator)\n    results.append({\n        'Model': model_name,\n        'Accuracy': test_accuracy,\n        'Precision': test_precision,\n        'Recall': test_recall,\n        'F1 Score': test_f1,\n        'Confusion Matrix': cm\n    })\n    test_accuracies.append(test_accuracy)\n\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:31:18.991425Z","iopub.execute_input":"2025-06-04T17:31:18.991622Z","iopub.status.idle":"2025-06-04T17:31:27.675891Z","shell.execute_reply.started":"2025-06-04T17:31:18.991608Z","shell.execute_reply":"2025-06-04T17:31:27.675290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Example: replace with your actual class order\nclass_names = ['AD', 'CONTROL', 'PD']\n\ndef generate_saliency_map(model, img_path, class_idx, image_size=(224, 224)):\n    img = load_img(img_path, target_size=image_size)\n    img_array = img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = img_array / 255.0  # Normalize the image\n\n    import tensorflow as tf\n    with tf.GradientTape() as tape:\n        inputs = tf.cast(img_array, tf.float32)\n        tape.watch(inputs)\n        predictions = model(inputs)\n        loss = predictions[:, class_idx]\n    grads = tape.gradient(loss, inputs)\n    abs_grads = tf.abs(grads)\n    saliency = tf.reduce_max(abs_grads, axis=-1)\n    saliency = saliency[0]\n    saliency = (saliency - tf.reduce_min(saliency)) / (tf.reduce_max(saliency) - tf.reduce_min(saliency) + 1e-10)\n    return saliency\n\ndef plot_saliency_map(img_path, saliency, predicted_class_name):\n    img = load_img(img_path)\n    img = np.array(img)\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.title(f'Original Image\\nPredicted: {predicted_class_name}')\n    plt.axis('off')\n    plt.subplot(1, 2, 2)\n    plt.imshow(saliency, cmap='hot')\n    plt.title('Saliency Map')\n    plt.axis('off')\n    plt.show()\n\n# Example test images (replace with your own paths)\ntest_images = [\n    '/kaggle/input/classifying-ad-and-pd-v3/3_cls_2/train/AD/AD_10.png',\n    '/kaggle/input/classifying-ad-and-pd-v3/3_cls_2/train/CONTROL/CONTROLAD_10.png',\n    '/kaggle/input/classifying-ad-and-pd-v3/3_cls_2/train/PD/PD_10.png'\n]\n\nimage_size = (224, 224)  # or your input size\n\nfor model_name, model in trained_models.items():\n    print(f\"\\n=== Model: {model_name} ===\")\n    for img_path in test_images:\n        img_arr = img_to_array(load_img(img_path, target_size=image_size)).reshape(1, 224, 224, 3) / 255.0\n        preds = model.predict(img_arr)\n        predicted_class_idx = np.argmax(preds[0])\n        predicted_class_name = class_names[predicted_class_idx]\n        print(f\"Image: {img_path}\")\n        print(f\"Predicted class: {predicted_class_name} (index: {predicted_class_idx}), Probabilities: {preds[0]}\")\n        saliency = generate_saliency_map(model, img_path, predicted_class_idx, image_size=image_size)\n        plot_saliency_map(img_path, saliency, predicted_class_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:31:27.676611Z","iopub.execute_input":"2025-06-04T17:31:27.676899Z","iopub.status.idle":"2025-06-04T17:31:30.714526Z","shell.execute_reply.started":"2025-06-04T17:31:27.676873Z","shell.execute_reply":"2025-06-04T17:31:30.713783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_each_model_accuracy(histories, initial_epochs=None):\n    \"\"\"\n    Plots training and validation accuracy for each model in separate figures.\n\n    Args:\n        histories (dict): Keys are model names, values are Keras History.history dicts.\n        initial_epochs (int or None): If provided, draws a vertical line at this epoch.\n    \"\"\"\n    for model_name, history in histories.items():\n        acc = history.get('accuracy') or history.get('acc')\n        val_acc = history.get('val_accuracy') or history.get('val_acc')\n        epochs = range(1, len(acc) + 1)\n\n        plt.figure(figsize=(8, 5))\n        plt.plot(epochs, acc, label=\"Train\", color='tab:blue', linestyle='-')\n        plt.plot(epochs, val_acc, label=\"Val\", color='tab:orange', linestyle='--')\n        if initial_epochs is not None:\n            plt.axvline(x=initial_epochs, linestyle=':', color='red', label='Layers Frozen/Unfrozen')\n        plt.title(f\"{model_name} - Training and Validation Accuracy\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        plt.grid(True)\n        plt.tight_layout()\n        plt.show()\n\n# Usage:\nplot_each_model_accuracy(histories, initial_epochs=initial_epochs)\n# If you don't have initial_epochs, just call: plot_each_model_accuracy(histories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:49:12.133014Z","iopub.execute_input":"2025-06-04T17:49:12.133703Z","iopub.status.idle":"2025-06-04T17:49:12.331270Z","shell.execute_reply.started":"2025-06-04T17:49:12.133677Z","shell.execute_reply":"2025-06-04T17:49:12.330537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Example model names in order\nmodel_names = ['VGG16', 'ResNet50', 'InceptionV3', 'Xception', 'EfficientNetB0']\n\n# Your test_accuracies list\n# test_accuracies = [0.81, 0.85, 0.83, 0.80, 0.88]  # Example\n\n# Find the index (and name) of the model with the highest accuracy\nbest_index = max(range(len(test_accuracies)), key=lambda i: test_accuracies[i])\nbest_accuracy = test_accuracies[best_index]\nbest_model = model_names[best_index]\nprint(f\"Highest test accuracy: {best_accuracy:.4f} ({best_model})\")\n\n# Plot\nplt.figure(figsize=(8, 5))\nbars = plt.bar(model_names, test_accuracies, color='limegreen')\nplt.ylabel(\"Test Accuracy\")\nplt.ylim(0, 1.05)\nplt.title(\"Test Accuracy for Each Pretrained Model\")\nfor bar, acc in zip(bars, test_accuracies):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{acc:.2%}\", \n             ha='center', va='bottom', fontsize=10)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:47:27.089526Z","iopub.execute_input":"2025-06-04T17:47:27.090089Z","iopub.status.idle":"2025-06-04T17:47:27.217151Z","shell.execute_reply.started":"2025-06-04T17:47:27.090065Z","shell.execute_reply":"2025-06-04T17:47:27.216558Z"}},"outputs":[],"execution_count":null}]}